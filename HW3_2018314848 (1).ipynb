{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fRqCsIZ3Jbeg",
        "outputId": "69805189-0a63-464a-bc5c-b64e1424f7dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.1+cu116'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1"
      ],
      "metadata": {
        "id": "SjBOCowEO2EI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = [1.0, 2.0, 3.0]\n",
        "x2 = [4.0, 5.0, 6.0]\n",
        "\n",
        "w1 = [[0.1, 0.2, 0.3, 0.4],\n",
        "      [0.5, 0.6, 0.7, 0.8],\n",
        "      [0.9, 1.0, 1.1, 1.2]]\n",
        "w2 = [[0.2, 0.3],\n",
        "      [0.4, 0.5],\n",
        "      [0.6, 0.7],\n",
        "      [0.8, 0.9]]"
      ],
      "metadata": {
        "id": "PaRw2qw7O0AH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch version\n",
        "x1_t = torch.tensor(x1)\n",
        "x2_t = torch.tensor(x2)\n",
        "w1_t = torch.tensor(w1, requires_grad=True)\n",
        "w2_t = torch.tensor(w2, requires_grad=True)\n",
        "\n",
        "z1_t = torch.matmul(torch.stack([x1_t, x2_t]), w1_t)\n",
        "print(z1_t)\n",
        "a1_t = F.relu(z1_t)\n",
        "print(a1_t)\n",
        "z2_t = torch.matmul(a1_t, w2_t)\n",
        "print(z2_t)\n",
        "a2_t = F.softmax(z2_t, dim=1)\n",
        "print('\\nfinal output of torch version:')\n",
        "print(a2_t)"
      ],
      "metadata": {
        "id": "fOYxqhNQUWdF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9dabbc6-2a8a-484b-806b-d3a8927435c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 3.8000,  4.4000,  5.0000,  5.6000],\n",
            "        [ 8.3000,  9.8000, 11.3000, 12.8000]], grad_fn=<MmBackward0>)\n",
            "tensor([[ 3.8000,  4.4000,  5.0000,  5.6000],\n",
            "        [ 8.3000,  9.8000, 11.3000, 12.8000]], grad_fn=<ReluBackward0>)\n",
            "tensor([[10.0000, 11.8800],\n",
            "        [22.6000, 26.8200]], grad_fn=<MmBackward0>)\n",
            "\n",
            "final output of torch version:\n",
            "tensor([[0.1324, 0.8676],\n",
            "        [0.0145, 0.9855]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy version\n",
        "x1_n = np.array(x1)\n",
        "x2_n = np.array(x2)\n",
        "w1_n = np.array(w1)\n",
        "w2_n = np.array(w2)\n",
        "\n",
        "def np_softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=1, keepdims=True)\n",
        "\n",
        "z1_n = np.matmul(np.array([x1_n, x2_n]), w1_n)\n",
        "print(z1_n)\n",
        "a1_n = np.maximum(z1_n, 0)\n",
        "print(a1_n)\n",
        "z2_n = np.matmul(a1_n, w2_n)\n",
        "print(z2_n)\n",
        "a2_n = np_softmax(z2_n)\n",
        "print('\\nfinal output of numpy version:')\n",
        "print(a2_n)"
      ],
      "metadata": {
        "id": "5MRKyXG2wP7A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a74282f2-663c-4844-b532-c181f01e191b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3.8  4.4  5.   5.6]\n",
            " [ 8.3  9.8 11.3 12.8]]\n",
            "[[ 3.8  4.4  5.   5.6]\n",
            " [ 8.3  9.8 11.3 12.8]]\n",
            "[[10.   11.88]\n",
            " [22.6  26.82]]\n",
            "\n",
            "final output of numpy version:\n",
            "[[0.13238887 0.86761113]\n",
            " [0.01448572 0.98551428]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2"
      ],
      "metadata": {
        "id": "R94GNnrTTBT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y1 = [0,1]\n",
        "y2 = [1,0]\n",
        "\n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "cl0iz45qTCFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch version\n",
        "y1_t = torch.Tensor(y1)\n",
        "y2_t = torch.Tensor(y2)\n",
        "y_t = torch.stack([y1_t,y2_t])\n",
        "\n",
        "def cross_entopy_loss_torch(y_true, y_pred):\n",
        "    return -torch.sum(y_true * torch.log(y_pred))\n",
        "    \n",
        "loss_t = cross_entopy_loss_torch(y_t, a2_t)\n",
        "loss_t.backward(retain_graph=True)\n",
        "dw1_t = w1_t.grad.clone()\n",
        "dw1_t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOudHJlwU7W2",
        "outputId": "5f0aa43c-b3d3-4ceb-842f-00ff47d371b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5714, 0.5714, 0.5714, 0.5714],\n",
              "        [0.6994, 0.6994, 0.6994, 0.6994],\n",
              "        [0.8274, 0.8274, 0.8274, 0.8274]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy version\n",
        "y1_n = np.array(y1)\n",
        "y2_n = np.array(y2)\n",
        "y_n = np.array([y1_n,y2_n])\n",
        "\n",
        "def cross_entopy_loss_np(y_true, y_pred):\n",
        "    return -np.sum(y_true * np.log(y_pred))\n",
        "\n",
        "loss_n = cross_entopy_loss_np(y_n, a2_n)\n",
        "\n",
        "# Calculate gradients\n",
        "dL_da2_n = (a2_n - y_n) / (a2_n * (1 - a2_n))\n",
        "dL_dz2_n = dL_da2_n * a2_n * (1 - a2_n)\n",
        "dL_dw2_n = np.matmul(a1_n.T, dL_dz2_n)\n",
        "dL_da1_n = np.matmul(dL_dz2_n, w2_n.T)\n",
        "dL_dz1_n = dL_da1_n * (z1_n > 0)\n",
        "dL_dw1_n = np.matmul(np.array([x1_n, x2_n]).T, dL_dz1_n)\n",
        "print(dL_dw1_n)"
      ],
      "metadata": {
        "id": "lNiKA7Hy31TV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "951ef9bc-290f-4b14-c7ab-670d627d417b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.38096682 0.38096682 0.38096682 0.38096682]\n",
            " [0.46627936 0.46627936 0.46627936 0.46627936]\n",
            " [0.5515919  0.5515919  0.5515919  0.5515919 ]]\n"
          ]
        }
      ]
    }
  ]
}